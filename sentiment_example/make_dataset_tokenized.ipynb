{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "dataset_all = load_from_disk('dataset_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"cyberagent/open-calm-medium\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_LENGTH = 512\n",
    "\n",
    "def tokenize(prompt, tokenizer: AutoTokenizer, cutoff_length=CUTOFF_LENGTH):\n",
    "    result = tokenizer(prompt + tokenizer.eos_token,\n",
    "                       truncation=True, \n",
    "                       max_length=cutoff_length,\n",
    "                       padding=True)\n",
    "    return {\n",
    "        'input_ids': result['input_ids'],\n",
    "        'attention_mask': result['attention_mask'],\n",
    "    }\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"{data_point['text']} \n",
    "\n",
    "### Response:\n",
    "{data_point['output']}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エクスペリアのGPS南北が逆になるのはデフォだったのか。 \n",
      "\n",
      "### Response:\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(dataset_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /mnt/data2/home/fujie/work/2023/finetune_llm/sentiment_example/dataset_all/cache-c53cad595e9ab484.arrow and /mnt/data2/home/fujie/work/2023/finetune_llm/sentiment_example/dataset_all/cache-fd7a09784287ab6b.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0125a4b7f3401fa6b54e2bdedc4804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da01e388f70f4910a9d279790fb53afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VAL_SET_SIZE = 4000\n",
    "\n",
    "train_val = dataset_all.train_test_split(\n",
    "    test_size=VAL_SET_SIZE, shuffle=True, seed=42)\n",
    "train_data = train_val[\"train\"]\n",
    "val_data = train_val[\"test\"]\n",
    "train_data = train_data.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n",
    "val_data = val_data.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val[\"train\"] = train_data\n",
    "train_val[\"test\"] = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b11ed38e184cd79c81c3b0552e6fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/300157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a57053ef64448f98cfbe02840ce8794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_val.save_to_disk('dataset_tokenized')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
